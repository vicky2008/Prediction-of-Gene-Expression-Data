{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the project from Tempus company. The dataset consists 16526 features and 1 response variable. There are 530 observations. So the number of features(predictors) is much larger than sample size. The goal is to create a predictive model for response variable. Basically, this project consists three parts, which are explonatory data analysis, dimension reduction, machine learning modeling.\n",
    "\n",
    "In the explorary data analysis, I check data type, data summary, dimensionality of the data. I can see response variable is binary data. So, logistic regression may be a choice for predictive modeling. I draw countplot of binary data and calculate the percentage of 1's for response variable. \n",
    "\n",
    "Since the dataset has too many features, I need to reduce data dimensionality before applying machine learning models.\n",
    "\n",
    "In the dimensional reduction part, I apply the PCA to reduce dimensionality of data. Then I apply logistic regression model for prediction. The precision is 0.87. To increase the precision, I also try some other ways to process data before applying PCA. I calculate correlations of each feature variable with response variable, then I remove some low correlated features. For the selected features , I apply PCA to reduce dimension further. Finally, I use logistic regression, support vector machine, random forest, stochastic gradient descent (SGD) learning, and XG-boosting method to make prediction model. And the highest precision is 92%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I import some useful libaries for data process, data visualization and machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import machine learning library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve,confusion_matrix,classification_report,accuracy_score,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DScasestudy_1.txt', delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V16553</th>\n",
       "      <th>V16554</th>\n",
       "      <th>V16555</th>\n",
       "      <th>V16556</th>\n",
       "      <th>V16557</th>\n",
       "      <th>V16558</th>\n",
       "      <th>V16559</th>\n",
       "      <th>V16560</th>\n",
       "      <th>V16561</th>\n",
       "      <th>V16562</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   response  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V16553  V16554  V16555  \\\n",
       "0         1   0   0   0   0   0   1   0   0   0  ...       1       0       0   \n",
       "1         1   0   0   0   0   0   1   0   0   0  ...       0       0       0   \n",
       "2         1   0   0   0   0   0   1   0   0   0  ...       0       0       0   \n",
       "3         1   0   0   0   0   0   1   0   0   0  ...       0       0       0   \n",
       "4         1   0   0   0   0   0   1   0   0   0  ...       0       0       0   \n",
       "\n",
       "   V16556  V16557  V16558  V16559  V16560  V16561  V16562  \n",
       "0       0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0       1  \n",
       "2       0       0       0       0       0       0       1  \n",
       "3       0       0       0       0       0       0       0  \n",
       "4       0       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 16563 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 16563)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530 entries, 0 to 529\n",
      "Columns: 16563 entries, response to V16562\n",
      "dtypes: int64(16563)\n",
      "memory usage: 67.0 MB\n"
     ]
    }
   ],
   "source": [
    "##data information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has more feature variables than observations (n<<p)\n",
    "By summarizing the data, I can see there are 530 observations and some statistics of all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V16553</th>\n",
       "      <th>V16554</th>\n",
       "      <th>V16555</th>\n",
       "      <th>V16556</th>\n",
       "      <th>V16557</th>\n",
       "      <th>V16558</th>\n",
       "      <th>V16559</th>\n",
       "      <th>V16560</th>\n",
       "      <th>V16561</th>\n",
       "      <th>V16562</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.0</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.0</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.0</td>\n",
       "      <td>...</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.0</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.0</td>\n",
       "      <td>530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.232075</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.030189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.020755</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.422556</td>\n",
       "      <td>0.096761</td>\n",
       "      <td>0.096761</td>\n",
       "      <td>0.043437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043437</td>\n",
       "      <td>0.171268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043437</td>\n",
       "      <td>0.142697</td>\n",
       "      <td>0.114270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 16563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         response          V1          V2          V3     V4          V5  \\\n",
       "count  530.000000  530.000000  530.000000  530.000000  530.0  530.000000   \n",
       "mean     0.232075    0.009434    0.009434    0.001887    0.0    0.020755   \n",
       "std      0.422556    0.096761    0.096761    0.043437    0.0    0.142697   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    0.0    1.000000   \n",
       "\n",
       "          V6          V7          V8     V9  ...      V16553  V16554  V16555  \\\n",
       "count  530.0  530.000000  530.000000  530.0  ...  530.000000   530.0   530.0   \n",
       "mean     1.0    0.001887    0.030189    0.0  ...    0.158491     0.0     0.0   \n",
       "std      0.0    0.043437    0.171268    0.0  ...    0.365545     0.0     0.0   \n",
       "min      1.0    0.000000    0.000000    0.0  ...    0.000000     0.0     0.0   \n",
       "25%      1.0    0.000000    0.000000    0.0  ...    0.000000     0.0     0.0   \n",
       "50%      1.0    0.000000    0.000000    0.0  ...    0.000000     0.0     0.0   \n",
       "75%      1.0    0.000000    0.000000    0.0  ...    0.000000     0.0     0.0   \n",
       "max      1.0    1.000000    1.000000    0.0  ...    1.000000     0.0     0.0   \n",
       "\n",
       "           V16556      V16557      V16558  V16559      V16560  V16561  \\\n",
       "count  530.000000  530.000000  530.000000   530.0  530.000000   530.0   \n",
       "mean     0.001887    0.020755    0.013208     0.0    0.003774     0.0   \n",
       "std      0.043437    0.142697    0.114270     0.0    0.061371     0.0   \n",
       "min      0.000000    0.000000    0.000000     0.0    0.000000     0.0   \n",
       "25%      0.000000    0.000000    0.000000     0.0    0.000000     0.0   \n",
       "50%      0.000000    0.000000    0.000000     0.0    0.000000     0.0   \n",
       "75%      0.000000    0.000000    0.000000     0.0    0.000000     0.0   \n",
       "max      1.000000    1.000000    1.000000     0.0    1.000000     0.0   \n",
       "\n",
       "           V16562  \n",
       "count  530.000000  \n",
       "mean     0.447170  \n",
       "std      0.497671  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 16563 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I check missing or null values in dataset,there is no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chech missing values\n",
    "df.isnull().sum().sum()\n",
    "#there is no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "By countplot of response variable, I can see there are 407 0's and 123 1's in the response data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    407\n",
       "1    123\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Data visualization\n",
    "sns.countplot(df['response'],data=df)\n",
    "df['response'].value_counts()\n",
    "df['response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculate the percentage of 1's in reponse variable, there are 23.2% of 1's. Since data is not balanced, in scikit learn, I use class_weight='balanced ' to blance data before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.20754716981132\n"
     ]
    }
   ],
   "source": [
    "#percentage of 1 in response\n",
    "print((df['response'].sum()/df['response'].count())*100)\n",
    "##23% of reponse are 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make PCA more efficiently for reducing dimensionality, I remove the features or columns with same entries. After doing this, there are 10894 entries in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530 entries, 0 to 529\n",
      "Columns: 10894 entries, response to V16562\n",
      "dtypes: int64(10894)\n",
      "memory usage: 44.1 MB\n"
     ]
    }
   ],
   "source": [
    "##drop some columns with same entries\n",
    "nunique = df.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "df.drop(cols_to_drop, inplace=True,axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In feature selection process, I calculate correlation and absolute value of correlation between each variable and response variable. I sort the absolute value of correlations and  make statistical summary of the correlations. We can see that most absoluate correlation are smaller than 0.08. I use it as threshold to filter out some lower correlated variables with response. Then I apply PCA and machine learning models on selected variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate correlation matrix\n",
    "correlations=df.corr(method='pearson')\n",
    "#cal correlation between features and response\n",
    "cor=correlations['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>abscorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10894.000000</td>\n",
       "      <td>10894.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.049189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.042853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.175642</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.033834</td>\n",
       "      <td>0.023902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.007415</td>\n",
       "      <td>0.038819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041912</td>\n",
       "      <td>0.067886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr       abscorr\n",
       "count  10894.000000  10894.000000\n",
       "mean       0.008214      0.049189\n",
       "std        0.064720      0.042853\n",
       "min       -0.175642      0.000083\n",
       "25%       -0.033834      0.023902\n",
       "50%       -0.007415      0.038819\n",
       "75%        0.041912      0.067886\n",
       "max        1.000000      1.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make dataframe of correlations\n",
    "corr1=pd.DataFrame({'features':cor.index, 'corr':cor.values})\n",
    "#add another col as abs of correlations\n",
    "corr1['abscorr']=corr1['corr'].abs()\n",
    "#rank abs correlations\n",
    "corr1.sort_values(by='abscorr',ascending=False)\n",
    "corr1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I select the feature variables with absolute value of correlations greater than 0.08. By doing this, there are only 1679 remaining features. Then I apply PCA on these selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530 entries, 0 to 529\n",
      "Columns: 1679 entries, response to V16553\n",
      "dtypes: int64(1679)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "f_select=corr1[corr1['abscorr']>0.08]['features']\n",
    "f_select=list(f_select)\n",
    "df_s=df[list(f_select)]\n",
    "df_s.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define X data frame by dropping response variable and define y as response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V17</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V27</th>\n",
       "      <th>V39</th>\n",
       "      <th>V46</th>\n",
       "      <th>V53</th>\n",
       "      <th>V71</th>\n",
       "      <th>V76</th>\n",
       "      <th>V104</th>\n",
       "      <th>...</th>\n",
       "      <th>V16460</th>\n",
       "      <th>V16485</th>\n",
       "      <th>V16497</th>\n",
       "      <th>V16502</th>\n",
       "      <th>V16509</th>\n",
       "      <th>V16532</th>\n",
       "      <th>V16535</th>\n",
       "      <th>V16542</th>\n",
       "      <th>V16545</th>\n",
       "      <th>V16553</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1678 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V17  V24  V25  V27  V39  V46  V53  V71  V76  V104  ...  V16460  V16485  \\\n",
       "0    0    0    0    0    0    0    0    0    1     0  ...       0       0   \n",
       "1    1    0    1    1    0    0    1    0    0     0  ...       0       0   \n",
       "2    0    0    0    0    0    0    0    0    0     0  ...       0       1   \n",
       "3    1    0    0    0    0    0    0    0    0     0  ...       0       0   \n",
       "4    1    0    0    0    0    0    0    0    0     0  ...       0       1   \n",
       "\n",
       "   V16497  V16502  V16509  V16532  V16535  V16542  V16545  V16553  \n",
       "0       0       1       0       0       0       0       0       1  \n",
       "1       0       0       1       0       0       1       0       0  \n",
       "2       0       0       0       0       0       0       0       0  \n",
       "3       0       0       1       0       0       0       0       0  \n",
       "4       0       1       1       0       0       1       0       0  \n",
       "\n",
       "[5 rows x 1678 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_s.drop('response',axis=1)\n",
    "y=df_s['response']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training set and test set by setting test size as 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I standarlize the data and use PCA to reduce data dimensions. I choose the principal components covering 97% of variations, there are 348 principal components. By PCA, data dimension is reduced from 1679 to 348."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "#Standarlize data\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "##apply PCA to reduce data dimension \n",
    "pca=PCA(0.97)\n",
    "pca.fit(X_train)\n",
    "print(pca.n_components_)\n",
    "##number of components\n",
    "X_train=pca.transform(X_train)\n",
    "X_test=pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting logistic regression model with solver 'lbfgs', the precision is 0.92. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95        83\n",
      "          1       0.89      0.74      0.81        23\n",
      "\n",
      "avg / total       0.92      0.92      0.92       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic regression model\n",
    "logReg=LogisticRegression(solver = 'lbfgs', class_weight = 'balanced')\n",
    "#logReg=LogisticRegression()\n",
    "logReg.fit(X_train,y_train)\n",
    "predictions=logReg.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the similar way, I use support vector machine model, the precision is 0.88, which is smaller than logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530 entries, 0 to 529\n",
      "Columns: 1106 entries, response to V16553\n",
      "dtypes: int64(1106)\n",
      "memory usage: 4.5 MB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       123\n",
      "          1       0.82      0.64      0.72        36\n",
      "\n",
      "avg / total       0.88      0.89      0.88       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_select=corr1[corr1['abscorr']>0.1]['features']\n",
    "f_select=list(f_select)\n",
    "df_s=df[list(f_select)]\n",
    "df_s.info()\n",
    "\n",
    "X=df_s.drop('response',axis=1)\n",
    "y=df_s['response']\n",
    "#X.head()\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "#SVM Classifier\n",
    "#param_grid = {'C': [1,10,20,30,40,50,60]} \n",
    "params_grid = {\"C\": [10**k for k in range(-3, 4)]}\n",
    "svc=LinearSVC(dual=False, random_state=42, class_weight='balanced')\n",
    "grid = GridSearchCV(svc,param_grid)\n",
    "grid.fit(X_train,y_train)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test,grid_predictions))\n",
    "#print('Accuracy on test set with raw data:{:.3f}'.format(grid.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also use random forest classifier, the precision is 0.88, which is same as support vector machine model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       123\n",
      "          1       0.94      0.44      0.60        36\n",
      "\n",
      "avg / total       0.88      0.87      0.85       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=200,max_depth=3,random_state=0)\n",
    "rfc.fit(X_train,y_train)\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I tried xgboost classifier, the precision is 0.90, which is better than random forest and SVM, but smaller than logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       123\n",
      "          1       0.92      0.61      0.73        36\n",
      "\n",
      "avg / total       0.90      0.90      0.89       159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/student/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model=XGBClassifier(max_depth=3, n_estimators=200, learning_rate=0.05)\n",
    "model.fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, I try SGD classifier, the precision is 0.87. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       123\n",
      "          1       0.89      0.44      0.59        36\n",
      "\n",
      "avg / total       0.87      0.86      0.84       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions=clf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, I try to use PCA without removing the lower correlated variables to response. Then, I use logistic regression to make prediction, the precision is 0.87, which is lower to the logitic regression model after removing lower correlated variables and PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       116\n",
      "          1       1.00      0.40      0.57        43\n",
      "\n",
      "avg / total       0.87      0.84      0.81       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X1=df.drop('response',axis=1)\n",
    "y1=df['response']\n",
    "X1.head()\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "\n",
    "#Standarlize data\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X1_train)\n",
    "X1_train=scaler.transform(X1_train)\n",
    "X1_test=scaler.transform(X1_test)\n",
    "##apply PCA to reduce data dimension \n",
    "pca=PCA(0.97)\n",
    "pca.fit(X1_train)\n",
    "print(pca.n_components_)\n",
    "##number of components\n",
    "X1_train=pca.transform(X1_train)\n",
    "X1_test=pca.transform(X1_test)\n",
    "#logistic regression model\n",
    "logReg=LogisticRegression(solver = 'lbfgs', class_weight = 'balanced')\n",
    "#logReg=LogisticRegression()\n",
    "logReg.fit(X1_train,y1_train)\n",
    "predictions=logReg.predict(X1_test)\n",
    "print(classification_report(y1_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: In this project, I achieve the goal of creating a predictive model for response variable. Basically, I do the explonatory data analysis, dimension reduction, machine learning modeling. Firstly, I remove some features which have lower correlations with response. Then for selected variables, I use PCA to reduce data dimensionality. Finally, I use different machine learning classifier to make prediction on test set. By comparing different performance of different classifer, logistic regression after removing lower correlated variables and PCA has highest precision, which is 92%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
